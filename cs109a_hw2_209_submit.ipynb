{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109A Introduction to Data Science: \n",
    "\n",
    "## Homework 2  AC 209 : Linear and k-NN Regression\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2018**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader\n",
    "\n",
    "<hr style=\"height:2pt\">\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in canvas.\n",
    "- Restart the kernel and run the whole notebook again before you submit. \n",
    "- If you submit individually and you have worked with someone, please include the name of your [one] partner below. \n",
    "- As much as possible, try and stick to the hints and functions we import at the top of the homework, as those are the ideas and tools the class supports and is aiming to teach. And if a problem specifies a particular library you're required to use that library, and possibly others from the import list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names of people you have worked with goes here: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "\n",
    "<div class='theme'>Linear Algebra, Accuracy, and Confidence Intervals </div>\n",
    "In this part of the homework, you will see how _uncertainty_ in the beta coefficients can directly impact our ability to make predictions with a linear regression model and how in general we can do inference on the predictors. You will explore a linear-algebra formula that tells us how accurately we've learned the beta parameters, going beyond simple SEs to describe the joint distribution of the betas. You'll see that the structure of the $X$ data can strongly impact how well we can learn the betas, and you'll determine desirable prroperties of the $X$ data.\n",
    "\n",
    "The data for this supplement are the same as in lab1, and are imported for you in the cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>disp</th>\n",
       "      <th>hp</th>\n",
       "      <th>drat</th>\n",
       "      <th>wt</th>\n",
       "      <th>qsec</th>\n",
       "      <th>vs</th>\n",
       "      <th>am</th>\n",
       "      <th>gear</th>\n",
       "      <th>carb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mazda RX4</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.620</td>\n",
       "      <td>16.46</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mazda RX4 Wag</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6</td>\n",
       "      <td>160.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.90</td>\n",
       "      <td>2.875</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Datsun 710</td>\n",
       "      <td>22.8</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>93</td>\n",
       "      <td>3.85</td>\n",
       "      <td>2.320</td>\n",
       "      <td>18.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hornet 4 Drive</td>\n",
       "      <td>21.4</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110</td>\n",
       "      <td>3.08</td>\n",
       "      <td>3.215</td>\n",
       "      <td>19.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hornet Sportabout</td>\n",
       "      <td>18.7</td>\n",
       "      <td>8</td>\n",
       "      <td>360.0</td>\n",
       "      <td>175</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.440</td>\n",
       "      <td>17.02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                name   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(\"data/cleaned_mtcars.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['mpg']].values\n",
    "X = df[['cyl','disp','hp','wt','qsec']]\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 5 [4 pts] </b> </div>\n",
    "\n",
    "**5.1** Fit a simple linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various values of `disp` and make a well-labeled plot showing\n",
    " 1. The observed values of `disp` and `mpg`.\n",
    " 2. The regression line.\n",
    " 3. The upper and lower bounds of the 95% confidence interval for the _predicted_ (not the observed) `mpg` at any given displacement.\n",
    " \n",
    "**5.2** Why do we have a confidence interval for our predicted value? Why isn't the prediction just a single number?\n",
    "\n",
    "**5.3** Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them? paying attention to the confidence interval (5.1.3) above?\n",
    "\n",
    "**5.4** Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.1 Fit a linear regression model predicting `mpg` via `disp`. Use the `FittedOLS.get_prediction().summary_frame()` method to access the confidence intervals for our prediction at various levels of `disp` and make a well-labled plot showing**\n",
    " 1. **The observed values of weight and mpg**\n",
    " 2. **The regression line**\n",
    " 3. **The upper and lower bounds of the 95% confidence interval for the _mean/predicted mpg_ at any given displacement**\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.005436</td>\n",
       "      <td>0.664391</td>\n",
       "      <td>21.648568</td>\n",
       "      <td>24.362303</td>\n",
       "      <td>16.227868</td>\n",
       "      <td>29.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23.005436</td>\n",
       "      <td>0.664391</td>\n",
       "      <td>21.648568</td>\n",
       "      <td>24.362303</td>\n",
       "      <td>16.227868</td>\n",
       "      <td>29.783003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25.148622</td>\n",
       "      <td>0.815316</td>\n",
       "      <td>23.483523</td>\n",
       "      <td>26.813720</td>\n",
       "      <td>18.302683</td>\n",
       "      <td>31.994561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18.966354</td>\n",
       "      <td>0.588977</td>\n",
       "      <td>17.763503</td>\n",
       "      <td>20.169205</td>\n",
       "      <td>12.217933</td>\n",
       "      <td>25.714774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14.762412</td>\n",
       "      <td>0.837509</td>\n",
       "      <td>13.051990</td>\n",
       "      <td>16.472833</td>\n",
       "      <td>7.905308</td>\n",
       "      <td>21.619515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  23.005436  0.664391      21.648568      24.362303     16.227868   \n",
       "1  23.005436  0.664391      21.648568      24.362303     16.227868   \n",
       "2  25.148622  0.815316      23.483523      26.813720     18.302683   \n",
       "3  18.966354  0.588977      17.763503      20.169205     12.217933   \n",
       "4  14.762412  0.837509      13.051990      16.472833      7.905308   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0     29.783003  \n",
       "1     29.783003  \n",
       "2     31.994561  \n",
       "3     25.714774  \n",
       "4     21.619515  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here \n",
    "df = df.rename(columns={\"Unnamed: 0\":\"car name\"})\n",
    "df.head()\n",
    "y_train = np.array(df.mpg)\n",
    "x_train = np.array(df.disp)\n",
    "x_train = sm.add_constant(x_train)\n",
    "regression = sm.OLS(y_train, x_train).fit()\n",
    "regression.get_prediction(x_train).summary_frame().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1c1b745e48>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (10, 6))\n",
    "fig.suptitle('Linear Regression and Confidence Interval')\n",
    "ax.plot(df.disp, df.mpg, 'o', label='Observed Data')\n",
    "grid = np.linspace(np.min(df.disp), np.max(df.disp), 100)\n",
    "ax.plot(grid, regression.get_prediction(sm.add_constant(grid)).summary_frame()['mean'],label='Regression Line')\n",
    "ax.plot(grid, regression.get_prediction(sm.add_constant(grid)).summary_frame()['mean_ci_lower'], color = 'black',label='CI lower bound')\n",
    "ax.plot(grid, regression.get_prediction(sm.add_constant(grid)).summary_frame()['mean_ci_upper'],'--' , color = 'grey',label='CI upper bound')\n",
    "ax.set_xlabel('disp')\n",
    "ax.set_ylabel('mpg')\n",
    "ax.legend(loc='upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.2 Why do we have a confidience interval for our predicted value? Why isn't the prediction just a single number?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "There are errors in our model and we can not get rid of them, so things do not happen for sure. We use a confidence interval to grab more information than a single number. We have no confidence that the next observation will fall right onto the single number but we are 95% confident that it will fall into the confidence interval of the predicted value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.3 Someone asks what `mpg` you would predict for a `disp` value of 400. What do you tell them, paying attention to the confidence interval (5.2.3) above?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>mean_se</th>\n",
       "      <th>mean_ci_lower</th>\n",
       "      <th>mean_ci_upper</th>\n",
       "      <th>obs_ci_lower</th>\n",
       "      <th>obs_ci_upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>13.113807</td>\n",
       "      <td>0.983136</td>\n",
       "      <td>11.105976</td>\n",
       "      <td>15.121638</td>\n",
       "      <td>6.176537</td>\n",
       "      <td>20.051077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
       "0  13.113807  0.983136      11.105976      15.121638      6.176537   \n",
       "\n",
       "   obs_ci_upper  \n",
       "0     20.051077  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "x_test = np.array([1, 400])\n",
    "regression.get_prediction(x_test).summary_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "For a disp value of 400, the 95% confidence interval of expectation of mpg is (11.105976, 15.121638). But if we just do one experiment, the 95% prediction interval of the newly picked mpg with disp 400 is (6.176537, 20.051077)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.4 Why does the 95% confidence interval for the predicted `mpg` appear to curve as we move away from the data's center?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "The variability of the sampling distribution of the predicted value $\\hat{y_{i}}$ is affected by how far the specific predictor $x_{i}$ is away from the mean predictor value $\\bar{x}$. \n",
    "\n",
    "All possible regression lines generated by OLS go through the data's center $(\\bar{x}, \\bar{y})$. However, they may have different slopes. If we imagine two different regression lines intersecting at the data's center, the y-coordinates are close when the x-coordinates are close to the intersection $(\\bar{x}, \\bar{y})$, but the ends of the regression lines extend to different directions. Therefore, the prediction interval gets wider as the x-coordinate moves away from $\\bar{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'><b> Question 6 [8 pts] </b></div>\n",
    "Hopefully, in the question above you recognized that uncertainty in the beta coefficients could impact the certainty of our predictions. In this question and the next, we're going to explore properties of the data that can make us more or less certain of the values of the betas.\n",
    "\n",
    "**6.1** Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.\n",
    "\n",
    "**6.2** The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. \n",
    "\n",
    "**6.3** Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.\n",
    "\n",
    "**6.4** Interpret the matrix formula above. At a minimum, discuss what affects our ability to estimate the betas accurately. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will be graded only on the specified minimum].\n",
    "\n",
    "**Hint**: we don't know $\\sigma^2$, but we can estimate them.<BR>\n",
    "**Hint**: remember that numpy's normal distribution expects a standard deviation and not a variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.1 Fit a multiple linear regression to the full X matrix (on the car data). That is, predict `mpg` using `cyl`,`disp`,`hp`,`wt`, and `qsec`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "regression7 = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.2 The formula for the covariance of the vector of betas, assuming the linear regression model holds, is:\n",
    "$${\\rm Cov}(\\beta) = \\sigma^2\\left(X^TX\\right)^{-1}.$$\n",
    "Compute and display this matrix for the car data. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 7.99244198e+01, -3.07189521e+00,  1.53550715e-02,\n",
       "         -6.81044250e-02,  4.02998464e+00, -3.76891870e+00],\n",
       "        [-3.07189521e+00,  4.15656681e-01, -3.33772420e-03,\n",
       "         -1.01645367e-03, -1.38010017e-01,  1.04389341e-01],\n",
       "        [ 1.53550715e-02, -3.33772420e-03,  1.15201605e-04,\n",
       "         -1.98165508e-05, -7.19076905e-03,  2.66624200e-04],\n",
       "        [-6.81044250e-02, -1.01645367e-03, -1.98165508e-05,\n",
       "          1.89384176e-04, -3.92076737e-03,  3.57445991e-03],\n",
       "        [ 4.02998464e+00, -1.38010017e-01, -7.19076905e-03,\n",
       "         -3.92076737e-03,  1.27438199e+00, -2.82476803e-01],\n",
       "        [-3.76891870e+00,  1.04389341e-01,  2.66624200e-04,\n",
       "          3.57445991e-03, -2.82476803e-01,  1.93064697e-01]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "y_pred = regression7.get_prediction(X).summary_frame()['mean']\n",
    "s = []\n",
    "for i in range(len(y)):\n",
    "    s.append(np.power((y_pred[i] -y[i]), 2))\n",
    "squaredse = np.mean(s)\n",
    "cov = squaredse*(np.matrix(X).T*np.matrix(X)).I\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.3 Verify that the SE reported by statsmodels matches the square root of the variance listed for that variable in your calculated covariance matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8.940045852499194, 0.6447144182055352, 0.010733201053817986, 0.013761692327588696, 1.128885288315206, 0.4393912805583459]\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "sbeta = []\n",
    "for i in range(6):\n",
    "    sbeta.append(np.sqrt(cov[i,i]))\n",
    "print(sbeta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.850</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   29.51</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 26 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>6.18e-10</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:23</td>     <th>  Log-Likelihood:    </th> <td> -72.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   156.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    26</td>      <th>  BIC:               </th> <td>   164.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     5</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   35.8736</td> <td>    9.918</td> <td>    3.617</td> <td> 0.001</td> <td>   15.487</td> <td>   56.261</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.1561</td> <td>    0.715</td> <td>   -1.616</td> <td> 0.118</td> <td>   -2.626</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>    0.0119</td> <td>    0.012</td> <td>    1.004</td> <td> 0.325</td> <td>   -0.013</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   -0.0158</td> <td>    0.015</td> <td>   -1.037</td> <td> 0.309</td> <td>   -0.047</td> <td>    0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   -4.2253</td> <td>    1.252</td> <td>   -3.374</td> <td> 0.002</td> <td>   -6.800</td> <td>   -1.651</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.2538</td> <td>    0.487</td> <td>    0.521</td> <td> 0.607</td> <td>   -0.748</td> <td>    1.256</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.925</td> <th>  Durbin-Watson:     </th> <td>   1.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.085</td> <th>  Jarque-Bera (JB):  </th> <td>   3.534</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.782</td> <th>  Prob(JB):          </th> <td>   0.171</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.453</td> <th>  Cond. No.          </th> <td>6.73e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 6.73e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.850\n",
       "Model:                            OLS   Adj. R-squared:                  0.821\n",
       "Method:                 Least Squares   F-statistic:                     29.51\n",
       "Date:                Wed, 26 Sep 2018   Prob (F-statistic):           6.18e-10\n",
       "Time:                        15:21:23   Log-Likelihood:                -72.003\n",
       "No. Observations:                  32   AIC:                             156.0\n",
       "Df Residuals:                      26   BIC:                             164.8\n",
       "Df Model:                           5                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         35.8736      9.918      3.617      0.001      15.487      56.261\n",
       "cyl           -1.1561      0.715     -1.616      0.118      -2.626       0.314\n",
       "disp           0.0119      0.012      1.004      0.325      -0.013       0.036\n",
       "hp            -0.0158      0.015     -1.037      0.309      -0.047       0.016\n",
       "wt            -4.2253      1.252     -3.374      0.002      -6.800      -1.651\n",
       "qsec           0.2538      0.487      0.521      0.607      -0.748       1.256\n",
       "==============================================================================\n",
       "Omnibus:                        4.925   Durbin-Watson:                   1.682\n",
       "Prob(Omnibus):                  0.085   Jarque-Bera (JB):                3.534\n",
       "Skew:                           0.782   Prob(JB):                        0.171\n",
       "Kurtosis:                       3.453   Cond. No.                     6.73e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 6.73e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regression7.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "The calculation result from the matrix is $[8.940045852499194, 0.6447144182055352, 0.010733201053817986, 0.013761692327588696, 1.128885288315206, 0.4393912805583459]$. \n",
    "\n",
    "The column of 'std err' in the regression result is $[9.918, 0.715, 0.012, 0.015, 1.252, 0.487]$. \n",
    "\n",
    "It is clear that they are quite close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.4 Interpret the matrix formula above. At a minimum, discuss what affects our ability to accurately estimate the betas. When would you expect two betas to have large/small covariances? [This is intended as an open-ended question. You will only be graded on the specified minimum].**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "The collinearity between  independent variables would affect our ability to estimate the betas. We expect two betas to have large covariances if there is a strong linear relationship between the two independent variables, which makes the betas difficult to estimate in regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='exercise'> <b> Question 7 [12 pts]: What affects our knowledge of the betas? </b></div> \n",
    "\n",
    "\n",
    "**7.1** Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution). What effects do you see on our ability to estimate the betas?\n",
    "\n",
    "**7.2** Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight. What change do you see in our certainty about weight's effect on mpg?\n",
    "\n",
    "**7.3** Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise. How well can we estimate the betas for this dataset, and which ones are correlated?\n",
    "\n",
    "**7.4** If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, or by deciding which columns to measure/keep), how would you like your features to relate? Specifically, how can you get as good an estimate of the betas as possible?\n",
    "\n",
    "**Hint**: Should introducing pure noise give us meaningfully more accurate beta values? <br>\n",
    "**Hint**: What happens if $X^TX$ is diagonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Answers\n",
    "\n",
    "**7.1  Create a separate dataset `edit1` with a new column `noise` that is totally independent of the other columns (random values from an exponential distribution) ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.852</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.817</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 26 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>2.99e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:23</td>     <th>  Log-Likelihood:    </th> <td> -71.762</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   157.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   167.8</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   37.6863</td> <td>   10.462</td> <td>    3.602</td> <td> 0.001</td> <td>   16.139</td> <td>   59.233</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.2787</td> <td>    0.751</td> <td>   -1.703</td> <td> 0.101</td> <td>   -2.825</td> <td>    0.268</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>    0.0113</td> <td>    0.012</td> <td>    0.933</td> <td> 0.360</td> <td>   -0.014</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   -0.0139</td> <td>    0.016</td> <td>   -0.885</td> <td> 0.385</td> <td>   -0.046</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   -4.1670</td> <td>    1.271</td> <td>   -3.278</td> <td> 0.003</td> <td>   -6.785</td> <td>   -1.549</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.1601</td> <td>    0.516</td> <td>    0.310</td> <td> 0.759</td> <td>   -0.903</td> <td>    1.224</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>noise</th> <td>    0.2863</td> <td>    0.465</td> <td>    0.615</td> <td> 0.544</td> <td>   -0.672</td> <td>    1.244</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 2.975</td> <th>  Durbin-Watson:     </th> <td>   1.643</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.226</td> <th>  Jarque-Bera (JB):  </th> <td>   2.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.650</td> <th>  Prob(JB):          </th> <td>   0.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.983</td> <th>  Cond. No.          </th> <td>7.02e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 7.02e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.852\n",
       "Model:                            OLS   Adj. R-squared:                  0.817\n",
       "Method:                 Least Squares   F-statistic:                     24.07\n",
       "Date:                Wed, 26 Sep 2018   Prob (F-statistic):           2.99e-09\n",
       "Time:                        15:21:23   Log-Likelihood:                -71.762\n",
       "No. Observations:                  32   AIC:                             157.5\n",
       "Df Residuals:                      25   BIC:                             167.8\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         37.6863     10.462      3.602      0.001      16.139      59.233\n",
       "cyl           -1.2787      0.751     -1.703      0.101      -2.825       0.268\n",
       "disp           0.0113      0.012      0.933      0.360      -0.014       0.036\n",
       "hp            -0.0139      0.016     -0.885      0.385      -0.046       0.019\n",
       "wt            -4.1670      1.271     -3.278      0.003      -6.785      -1.549\n",
       "qsec           0.1601      0.516      0.310      0.759      -0.903       1.224\n",
       "noise          0.2863      0.465      0.615      0.544      -0.672       1.244\n",
       "==============================================================================\n",
       "Omnibus:                        2.975   Durbin-Watson:                   1.643\n",
       "Prob(Omnibus):                  0.226   Jarque-Bera (JB):                2.255\n",
       "Skew:                           0.650   Prob(JB):                        0.324\n",
       "Kurtosis:                       2.983   Cond. No.                     7.02e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 7.02e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit1 = df.copy()\n",
    "edit1['noise'] = np.random.exponential(1,len(df))\n",
    "y = edit1[['mpg']].values\n",
    "X = edit1[['cyl','disp','hp','wt','qsec','noise']]\n",
    "X = sm.add_constant(X)\n",
    "regression7_1 = sm.OLS(y, X).fit()\n",
    "regression7_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.55123959e+01, -3.48463750e+00,  1.26496302e-02,\n",
       "         -5.99963258e-02,  4.18764564e+00, -4.06324443e+00,\n",
       "          1.07077457e+00],\n",
       "        [-3.48463750e+00,  4.40469959e-01, -3.12044760e-03,\n",
       "         -1.48094497e-03, -1.50680270e-01,  1.26540729e-01,\n",
       "         -7.24191347e-02],\n",
       "        [ 1.26496302e-02, -3.12044760e-03,  1.14387411e-04,\n",
       "         -2.21111477e-05, -7.16303394e-03,  3.90678166e-04,\n",
       "         -3.91077127e-04],\n",
       "        [-5.99963258e-02, -1.48094497e-03, -2.21111477e-05,\n",
       "          1.93977029e-04, -3.63447966e-03,  3.15446382e-03,\n",
       "          1.12000852e-03],\n",
       "        [ 4.18764564e+00, -1.50680270e-01, -7.16303394e-03,\n",
       "         -3.63447966e-03,  1.26236526e+00, -2.89522322e-01,\n",
       "          3.43929869e-02],\n",
       "        [-4.06324443e+00,  1.26540729e-01,  3.90678166e-04,\n",
       "          3.15446382e-03, -2.89522322e-01,  2.08308503e-01,\n",
       "         -5.53605250e-02],\n",
       "        [ 1.07077457e+00, -7.24191347e-02, -3.91077127e-04,\n",
       "          1.12000852e-03,  3.43929869e-02, -5.53605250e-02,\n",
       "          1.69100722e-01]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regression7_1.get_prediction(X).summary_frame()['mean']\n",
    "s = []\n",
    "for i in range(len(y)):\n",
    "    s.append(np.power((y_pred[i] -y[i]), 2))\n",
    "squaredse = np.mean(s)\n",
    "cov = squaredse*(np.matrix(X).T*np.matrix(X)).I\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "The standard errors of the betas all increase a little bit. In the covariance matrix, the absolute values of most elements also increase, which implies stronger correlations among betas. Therefore, adding a random noise slightly diminishes our ability to estimate the betas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.2 Create a separate dataset `edit2` with a new column `ratio` that is the ratio of a car's horsepower to its weight ... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.851</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.815</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   23.73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 26 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>3.46e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:24</td>     <th>  Log-Likelihood:    </th> <td> -71.955</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   157.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   168.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   38.1047</td> <td>   12.967</td> <td>    2.939</td> <td> 0.007</td> <td>   11.398</td> <td>   64.811</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.1980</td> <td>    0.744</td> <td>   -1.610</td> <td> 0.120</td> <td>   -2.731</td> <td>    0.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>    0.0124</td> <td>    0.012</td> <td>    1.015</td> <td> 0.320</td> <td>   -0.013</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   -0.0054</td> <td>    0.041</td> <td>   -0.131</td> <td> 0.897</td> <td>   -0.090</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   -4.6785</td> <td>    2.087</td> <td>   -2.242</td> <td> 0.034</td> <td>   -8.977</td> <td>   -0.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.2238</td> <td>    0.508</td> <td>    0.440</td> <td> 0.664</td> <td>   -0.823</td> <td>    1.271</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ratio</th> <td>   -0.0357</td> <td>    0.130</td> <td>   -0.274</td> <td> 0.786</td> <td>   -0.304</td> <td>    0.232</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 4.333</td> <th>  Durbin-Watson:     </th> <td>   1.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.115</td> <th>  Jarque-Bera (JB):  </th> <td>   3.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.743</td> <th>  Prob(JB):          </th> <td>   0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.330</td> <th>  Cond. No.          </th> <td>8.73e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 8.73e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.851\n",
       "Model:                            OLS   Adj. R-squared:                  0.815\n",
       "Method:                 Least Squares   F-statistic:                     23.73\n",
       "Date:                Wed, 26 Sep 2018   Prob (F-statistic):           3.46e-09\n",
       "Time:                        15:21:24   Log-Likelihood:                -71.955\n",
       "No. Observations:                  32   AIC:                             157.9\n",
       "Df Residuals:                      25   BIC:                             168.2\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         38.1047     12.967      2.939      0.007      11.398      64.811\n",
       "cyl           -1.1980      0.744     -1.610      0.120      -2.731       0.335\n",
       "disp           0.0124      0.012      1.015      0.320      -0.013       0.038\n",
       "hp            -0.0054      0.041     -0.131      0.897      -0.090       0.079\n",
       "wt            -4.6785      2.087     -2.242      0.034      -8.977      -0.380\n",
       "qsec           0.2238      0.508      0.440      0.664      -0.823       1.271\n",
       "ratio         -0.0357      0.130     -0.274      0.786      -0.304       0.232\n",
       "==============================================================================\n",
       "Omnibus:                        4.333   Durbin-Watson:                   1.719\n",
       "Prob(Omnibus):                  0.115   Jarque-Bera (JB):                3.092\n",
       "Skew:                           0.743   Prob(JB):                        0.213\n",
       "Kurtosis:                       3.330   Cond. No.                     8.73e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 8.73e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit2 = df.copy()\n",
    "edit2['ratio'] = edit2['hp']/edit2['wt']\n",
    "y = edit2[['mpg']].values\n",
    "X = edit2[['cyl','disp','hp','wt','qsec','ratio']]\n",
    "X = sm.add_constant(X)\n",
    "regression7_2 = sm.OLS(y, X).fit()\n",
    "regression7_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 1.31364204e+02, -4.03411322e+00,  2.64003168e-02,\n",
       "          1.73895316e-01, -6.48109273e+00, -4.45327514e+00,\n",
       "         -8.27216976e-01],\n",
       "        [-4.03411322e+00,  4.32669644e-01, -3.53619428e-03,\n",
       "         -5.55849937e-03,  5.97565360e-02,  1.17152717e-01,\n",
       "          1.55494331e-02],\n",
       "        [ 2.64003168e-02, -3.53619428e-03,  1.17236263e-04,\n",
       "          3.21362989e-05, -9.42244866e-03,  1.16522070e-04,\n",
       "         -1.77534775e-04],\n",
       "        [ 1.73895316e-01, -5.55849937e-03,  3.21362989e-05,\n",
       "          1.32011220e-03, -5.30309602e-02,  3.08890097e-04,\n",
       "         -3.87032899e-03],\n",
       "        [-6.48109273e+00,  5.97565360e-02, -9.42244866e-03,\n",
       "         -5.30309602e-02,  3.40347944e+00, -1.40300725e-01,\n",
       "          1.68053347e-01],\n",
       "        [-4.45327514e+00,  1.17152717e-01,  1.16522070e-04,\n",
       "          3.08890097e-04, -1.40300725e-01,  2.01849775e-01,\n",
       "          1.11352886e-02],\n",
       "        [-8.27216976e-01,  1.55494331e-02, -1.77534775e-04,\n",
       "         -3.87032899e-03,  1.68053347e-01,  1.11352886e-02,\n",
       "          1.32409568e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regression7_2.get_prediction(X).summary_frame()['mean']\n",
    "s = []\n",
    "for i in range(len(y)):\n",
    "    s.append(np.power((y_pred[i] -y[i]), 2))\n",
    "squaredse = np.mean(s)\n",
    "cov = squaredse*(np.matrix(X).T*np.matrix(X)).I\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "There is an inflation in the standard error of the effect exerted by the variable 'weight', and the p-value of the effect of 'weight' increases from 0.002 to 0.034, meaning that we are less certain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.3 Create a separate dataset `edit3` with a new column `combo` that is horsepower+displacement+weight+ Normal(0,.01) noise... **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.818</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.18</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Wed, 26 Sep 2018</td> <th>  Prob (F-statistic):</th> <td>2.84e-09</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>15:21:24</td>     <th>  Log-Likelihood:    </th> <td> -71.697</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    32</td>      <th>  AIC:               </th> <td>   157.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    25</td>      <th>  BIC:               </th> <td>   167.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   37.8708</td> <td>   10.423</td> <td>    3.633</td> <td> 0.001</td> <td>   16.404</td> <td>   59.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cyl</th>   <td>   -1.2953</td> <td>    0.750</td> <td>   -1.728</td> <td> 0.096</td> <td>   -2.840</td> <td>    0.249</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>disp</th>  <td>   36.3484</td> <td>   52.321</td> <td>    0.695</td> <td> 0.494</td> <td>  -71.408</td> <td>  144.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hp</th>    <td>   36.3186</td> <td>   52.318</td> <td>    0.694</td> <td> 0.494</td> <td>  -71.432</td> <td>  144.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wt</th>    <td>   32.2091</td> <td>   52.477</td> <td>    0.614</td> <td> 0.545</td> <td>  -75.869</td> <td>  140.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>qsec</th>  <td>    0.1688</td> <td>    0.507</td> <td>    0.333</td> <td> 0.742</td> <td>   -0.876</td> <td>    1.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>combo</th> <td>  -36.3352</td> <td>   52.319</td> <td>   -0.694</td> <td> 0.494</td> <td> -144.088</td> <td>   71.418</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.973</td> <th>  Durbin-Watson:     </th> <td>   1.608</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.137</td> <th>  Jarque-Bera (JB):  </th> <td>   2.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.633</td> <th>  Prob(JB):          </th> <td>   0.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.560</td> <th>  Cond. No.          </th> <td>1.20e+05</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+05. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.853\n",
       "Model:                            OLS   Adj. R-squared:                  0.818\n",
       "Method:                 Least Squares   F-statistic:                     24.18\n",
       "Date:                Wed, 26 Sep 2018   Prob (F-statistic):           2.84e-09\n",
       "Time:                        15:21:24   Log-Likelihood:                -71.697\n",
       "No. Observations:                  32   AIC:                             157.4\n",
       "Df Residuals:                      25   BIC:                             167.7\n",
       "Df Model:                           6                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         37.8708     10.423      3.633      0.001      16.404      59.337\n",
       "cyl           -1.2953      0.750     -1.728      0.096      -2.840       0.249\n",
       "disp          36.3484     52.321      0.695      0.494     -71.408     144.105\n",
       "hp            36.3186     52.318      0.694      0.494     -71.432     144.069\n",
       "wt            32.2091     52.477      0.614      0.545     -75.869     140.287\n",
       "qsec           0.1688      0.507      0.333      0.742      -0.876       1.214\n",
       "combo        -36.3352     52.319     -0.694      0.494    -144.088      71.418\n",
       "==============================================================================\n",
       "Omnibus:                        3.973   Durbin-Watson:                   1.608\n",
       "Prob(Omnibus):                  0.137   Jarque-Bera (JB):                2.556\n",
       "Skew:                           0.633   Prob(JB):                        0.279\n",
       "Kurtosis:                       3.560   Cond. No.                     1.20e+05\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+05. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "edit3 = df.copy()\n",
    "edit3['combo'] = edit3['hp'] +  edit3['disp'] + edit3['wt'] + np.random.normal(0,0.01,len(df))\n",
    "y = edit3[['mpg']].values\n",
    "X = edit3[['cyl','disp','hp','wt','qsec','combo']]\n",
    "X = sm.add_constant(X)\n",
    "regression7_3 = sm.OLS(y, X).fit()\n",
    "regression7_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 8.48728007e+01, -3.46425818e+00,  1.17565362e+02,\n",
       "          1.17477050e+02,  1.21820890e+02, -3.97260956e+00,\n",
       "         -1.17546442e+02],\n",
       "        [-3.46425818e+00,  4.39200975e-01, -8.19950445e+00,\n",
       "         -8.19677867e+00, -8.35372269e+00,  1.21589896e-01,\n",
       "          8.19596108e+00],\n",
       "        [ 1.17565362e+02, -8.19950445e+00,  2.13863334e+03,\n",
       "          2.13851619e+03,  2.14439139e+03, -5.00341771e+00,\n",
       "         -2.13856308e+03],\n",
       "        [ 1.17477050e+02, -8.19677866e+00,  2.13851619e+03,\n",
       "          2.13839939e+03,  2.14427727e+03, -4.99989871e+00,\n",
       "         -2.13844607e+03],\n",
       "        [ 1.21820890e+02, -8.35372269e+00,  2.14439139e+03,\n",
       "          2.14427727e+03,  2.15142947e+03, -5.29429811e+00,\n",
       "         -2.14432811e+03],\n",
       "        [-3.97260956e+00,  1.21589896e-01, -5.00341771e+00,\n",
       "         -4.99989871e+00, -5.29429811e+00,  2.01117338e-01,\n",
       "          5.00351518e+00],\n",
       "        [-1.17546442e+02,  8.19596108e+00, -2.13856308e+03,\n",
       "         -2.13844607e+03, -2.14432811e+03,  5.00351517e+00,\n",
       "          2.13849294e+03]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = regression7_3.get_prediction(X).summary_frame()['mean']\n",
    "s = []\n",
    "for i in range(len(y)):\n",
    "    s.append(np.power((y_pred[i] -y[i]), 2))\n",
    "squaredse = np.mean(s)\n",
    "cov = squaredse*(np.matrix(X).T*np.matrix(X)).I\n",
    "cov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*\n",
    "\n",
    "The standard errors of the effects of horsepower, displacement and weight all increase to really large values and we cannot estimate the betas well in this situation. Predictors disp, hp, wt and combo are correlated in this case. We can see that the 3rd, 4th and 5th column of the covariance matrix is quite large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7.4 If you could choose the different features in your data (either because you're running a lab experiment manipulating the X values, ... **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*your answer here*\n",
    "\n",
    "Firstly, there sould not be strong linear relationships among different features. Collinearity leads to large standard errors of betas, which diminishes our confidence and certainty of the model. \n",
    "\n",
    "Secondly, the features should all contribute to explanation of variance of dependent variable. Pure noise in the model will also increase the standard errors of betas in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
